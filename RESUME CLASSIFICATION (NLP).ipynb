{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff2a0cc",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969607e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import docx\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import spacy\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from spacy import displacy\n",
    "import docx\n",
    "import spacy\n",
    "from spacy import schemas\n",
    "from spacy import Dict\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import textract\n",
    "import antiword\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "from spacy.matcher import Matcher\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0b210",
   "metadata": {},
   "source": [
    "### IMPORT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2c3b90",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\DS PROJECT NLP\\\\intership_resumes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14360/837831546.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\DS PROJECT NLP\\intership_resumes.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\DS PROJECT NLP\\Peoplesoft_Resumes.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\DS PROJECT NLP\\React_Developer_resumes.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\DS PROJECT NLP\\SQLDeveloperLightning_Resumes.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\DS PROJECT NLP\\workday_resumes.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\DS PROJECT NLP\\\\intership_resumes.csv'"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"D:\\DS PROJECT NLP\\intership_resumes.csv\")\n",
    "data2 = pd.read_csv(\"D:\\DS PROJECT NLP\\Peoplesoft_Resumes.csv\")\n",
    "data3 = pd.read_csv(\"D:\\DS PROJECT NLP\\React_Developer_resumes.csv\")\n",
    "data4 = pd.read_csv(\"D:\\DS PROJECT NLP\\SQLDeveloperLightning_Resumes.csv\")\n",
    "data5 = pd.read_csv(\"D:\\DS PROJECT NLP\\workday_resumes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c193b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Resume = pd.concat([data1,data2,data3,data4,data5],axis=0)\n",
    "Resume = Resume.reset_index()\n",
    "Resume = Resume.drop(columns='Number',axis=0)\n",
    "Resume = Resume.drop(columns='index',axis=0)\n",
    "Resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af177081",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4de3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Resume.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88daa47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Resume.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa00c9",
   "metadata": {},
   "source": [
    "### Calculating each Characterstic in dataframe BEFORE CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_characters=Resume[\"CV\"].apply(len)\n",
    "before_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of characters before cleaning dataset :',before_characters.sum())\n",
    "print('Mean of each characters before cleaning the dataset:',before_characters.mean())\n",
    "print('Median of characters before cleaning the dataset:',before_characters.median())\n",
    "print('Standard Deviation of characters before cleaning the dataset:',before_characters.std())\n",
    "print('skew of characters before cleaning the dataset:',before_characters.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc188a40",
   "metadata": {},
   "source": [
    "### Calculating each WORD Characterstic in dataframe BEFORE cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3745b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_words = Resume['CV'].apply(lambda x: len(str(x).split(' ')))\n",
    "before_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae134135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of Word in dataset before cleaning:',before_words.sum())\n",
    "print('Mean of each Word in dataset before cleaning:',before_words.mean())\n",
    "print('Median of Word in dataset before cleaning:',before_words.median())\n",
    "print('Standard Deviation of Word in dataset before cleaning:',before_words.std())\n",
    "print('skew of Word dataset before cleaning:',before_words.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59734f95",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5f824",
   "metadata": {},
   "source": [
    "##### We will perform label encoding to convert category variable from string datatype to float datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7bb86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_encoder = LabelEncoder()\n",
    "Resume[\"Encoded_Skill\"] = le_encoder.fit_transform(Resume[\"Label\"])\n",
    "Resume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c74546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Resume.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2de206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Displaying the distinct categories of resume -\")\n",
    "print(Resume.Label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501b5d8",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87532f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #REGULAR EXPRESSION\n",
    "import string\n",
    "\n",
    "def clean_text(CV):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    CV = CV.lower()\n",
    "    CV = re.sub('\\[.*?\\]', '', CV)\n",
    "    CV = re.sub('[%s]' % re.escape(string.punctuation), '', CV)\n",
    "    CV = re.sub('\\w*\\d\\w*', '', CV)\n",
    "    CV = re.sub(\"[0-9\" \"]+\",\" \",CV)\n",
    "    CV = re.sub('[‘’“”…]', '', CV)\n",
    "    return CV\n",
    "\n",
    "clean = lambda x: clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd398200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Resume['CV'] = Resume.CV.apply(clean)\n",
    "Resume.CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3a8f46",
   "metadata": {},
   "source": [
    "### Word frequency BEFORE removal of STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14816305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Word Frequency\n",
    "frequency = pd.Series(' '.join(Resume['CV']).split()).value_counts()[:20] #For top 20\n",
    "frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247c16e",
   "metadata": {},
   "source": [
    "### Removing STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd765777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "Resume['CV'] = Resume['CV'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c3b4a",
   "metadata": {},
   "source": [
    "### Word frequency AFTER removal of STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef489a11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frequency_Sw = pd.Series(' '.join(Resume['CV']).split()).value_counts()[:20] # for top 20\n",
    "frequency_Sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547d32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e87bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95eaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143af6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7491b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd797db",
   "metadata": {},
   "source": [
    "### Performing A NER (Using Spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "text=nlp(Resume[\"CV\"][0])\n",
    "displacy.render(text, style = \"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3343205",
   "metadata": {},
   "source": [
    "#### First take a look at the number of Characters present in each sentence. This can give us a rough idea about the resume length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd299a9",
   "metadata": {},
   "source": [
    "##### Calculating each Characterstic in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ffae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters=Resume[\"CV\"].apply(len)\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of characters dataset:',characters.sum())\n",
    "print('Mean of each characters in datset:',characters.mean())\n",
    "print('Median of characters in dataset:',characters.median())\n",
    "print('Standard Deviation of characters in dataset:',characters.std())\n",
    "print('skew of characters dataset:',characters.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.distplot(x = characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d352c8",
   "metadata": {},
   "source": [
    "#### Calculating each Word Characterstic in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e664b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = Resume['CV'].apply(lambda x: len(str(x).split(' ')))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of Word in dataset:',words.sum())\n",
    "print('Mean of each Word in datset:',words.mean())\n",
    "print('Median of Word in dataset:',words.median())\n",
    "print('Standard Deviation of Word in dataset:',words.std())\n",
    "print('skew of Word dataset:',words.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36054929",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(x = words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b1021",
   "metadata": {},
   "source": [
    "### VISUALIZATION OF DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"The distinct categories of resumes\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(y=\"Label\", data=Resume,palette=(\"Set2\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "targetCounts = Resume.Label.value_counts()\n",
    "targetLabels  = Resume.Label.unique()\n",
    "# Make square figures and axes\n",
    "plt.figure(1, figsize=(25,25))\n",
    "the_grid = GridSpec(2, 2)\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('plasma')\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99','#c2c2f0']\n",
    "plt.subplot(the_grid[0, 1], aspect=1, title='CATEGORY DISTRIBUTION')\n",
    "\n",
    "\n",
    "source_pie = plt.pie(targetCounts, labels=targetLabels, autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d96094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72d2cb95",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0dc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =['using','Workday','Experience','PeopleSoft',\n",
    " 'experience','SQL','Application','data','Server',\n",
    " 'business','Project','reports','like','HCM','Worked',\n",
    " 'knowledge','Involved','various','Good', 'Reports','React','EIB','integrations','Web','system','creating','issues',\n",
    " 'Created', 'Responsibilities','Process','process','support', \n",
    " 'application','new','People','I','team','working', \n",
    " 'Database','database','Integration','Domains','client', \n",
    " 'requirements','Core',  'Business', \n",
    "'Oracle','Report', 'Developer', 'Data']\n",
    "indices = np.random.zipf(1.6, size=500).astype(np.int) % len(words)\n",
    "tw = np.array(words)[indices]\n",
    "\n",
    "tf = Counter(tw)\n",
    "\n",
    "y = [count for tag, count in tf.most_common(50)]\n",
    "x = [tag for tag, count in tf.most_common(50)]\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x, y, color=['gold','lightcoral', 'lightskyblue'])\n",
    "plt.title(\"Word frequencies in Resume Data in Log Scale\")\n",
    "plt.ylabel(\"Frequency (log scale)\")\n",
    "plt.yscale('symlog') # optionally set a log scale for the y-axis\n",
    "plt.xticks(rotation=90)\n",
    "for i, (tag, count) in enumerate(tf.most_common(50)):\n",
    "    plt.text(i, count, f' {count} ', rotation=90,\n",
    "             ha='center', va='top' if i < 10 else 'bottom', color='white' if i < 10 else 'black')\n",
    "plt.xlim(-0.6, len(x)-0.4) # optionally set tighter x lims\n",
    "plt.tight_layout() # change the whitespace such that all labels fit nicely\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7375dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordBarGraphFunction_1(df,column,title):\n",
    "    topic_words = [ z.lower() for y in\n",
    "                       [ x.split() for x in df[column] if isinstance(x, str)]\n",
    "                       for z in y]\n",
    "    word_count_dict = dict(Counter(topic_words))\n",
    "    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n",
    "    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sns.barplot(x=np.arange(20),y= [word_count_dict[w] for w in reversed(popular_words_nonstop[0:20])])\n",
    "    plt.xticks([x + 0.5 for x in range(20)], reversed(popular_words_nonstop[0:20]),rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "wordBarGraphFunction_1(Resume,\"CV\",\"Most frequent Words \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca899ff1",
   "metadata": {},
   "source": [
    "#### WORDCLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed74854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e932da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wordcloud\n",
    "stopwords = STOPWORDS\n",
    "stopwords.add('will')\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, background_color='black', max_words=100,colormap='Set2',stopwords=stopwords).generate(str(Resume))\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451e661",
   "metadata": {},
   "source": [
    "#### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredText = Resume[\"CV\"]\n",
    "requiredTarget = Resume[\"Encoded_Skill\"].values\n",
    "Countvectorizer=CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',stop_words = 'english')\n",
    "bag = Countvectorizer.fit_transform(requiredText)\n",
    "Countvectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60215d3",
   "metadata": {},
   "source": [
    "#### VECTORIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e609488",
   "metadata": {},
   "source": [
    "#### COUNT VECTORIZER tells the frequency of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(min_df = 1, max_df = 0.9)\n",
    "count_vect = vectorizer1.fit_transform(Resume[\"CV\"])\n",
    "word_freq_df = pd.DataFrame({'term': vectorizer1.get_feature_names(), 'occurrences':np.asarray(count_vect.sum(axis=0)).ravel().tolist()})\n",
    "word_freq_df['frequency'] = word_freq_df['occurrences']/np.sum(word_freq_df['occurrences'])\n",
    "word_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb490d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(x =[word_freq_df['frequency']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749a54b",
   "metadata": {},
   "source": [
    "#### TFIDF - Term frequency inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe937dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7785ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english',max_features=1500)\n",
    "word_vectorizer.fit(requiredText)\n",
    "WordFeatures = word_vectorizer.transform(requiredText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b55f1e6",
   "metadata": {},
   "source": [
    "### Model Building || Model Training || Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee0242",
   "metadata": {},
   "source": [
    "#### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(WordFeatures, requiredTarget, random_state=0, test_size=0.2)\n",
    "print(\"X Train shape:\",x_train.shape)\n",
    "print(\"Y Train shape:\",y_train.shape)\n",
    "print(\"x Test shape:\",x_test.shape)\n",
    "print(\"y Test shape:\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823011f0",
   "metadata": {},
   "source": [
    "### 1. LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2818abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING NECESSARY LIBRARIES FOR LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,accuracy_score,precision_score,recall_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a769d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Training Data\n",
    "pred_train_log = logistic_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "train_acc_log = np.mean(pred_train_log==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN LOGISTIC REGRESSION:\", train_acc_log)\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_log = logistic_classifier.predict(x_test)\n",
    "#Accuracy On Test Data\n",
    "test_acc_log = np.mean(pred_test_log==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN LOGISTIC REGRESSION:\",test_acc_log )\n",
    "\n",
    "#Confusion Matrix\n",
    "logistic_cm = confusion_matrix(y_test,pred_test_log)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF LOGISTIC REGRESSION:\\n\", classification_report(y_test,pred_test_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log = round(accuracy_score(y_test,pred_test_log),4)\n",
    "precision_log = round(precision_score(y_test,pred_test_log,average = 'macro'),4)\n",
    "recall_log = round(recall_score(y_test,pred_test_log,average = 'macro'),4)\n",
    "f1_log = round(f1_score(y_test,pred_test_log,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_log )\n",
    "print('Precision Score  : ',precision_log )\n",
    "print('Recall Score     : ', recall_log)\n",
    "print('f1-Score         : ',f1_log )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318803d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c5e442",
   "metadata": {},
   "source": [
    "### 2. DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING NECESSARY LIBRARIES FOR DECISION TREE\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0f3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT_classifier = DecisionTreeClassifier(criterion = 'entropy', max_depth=2)\n",
    "DT_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_dt = DT_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "train_acc_dt = np.mean(pred_train_dt==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN DECISION TREE:\",train_acc_dt )\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_dt = DT_classifier.predict(x_test)\n",
    "#Accuracy on Test Data\n",
    "test_acc_dt = np.mean(pred_test_dt==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN DECISION TREE:\",test_acc_dt )\n",
    "\n",
    "#Confusion Matrix\n",
    "dt_cm = confusion_matrix(y_test,pred_test_dt)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF DECISION TREE:\\n\", classification_report(y_test,pred_test_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dt = round(accuracy_score(y_test,pred_test_dt),4)\n",
    "precision_dt = round(precision_score(y_test,pred_test_dt,average = 'macro'),4)\n",
    "recall_dt = round(recall_score(y_test,pred_test_dt,average = 'macro'),4)\n",
    "f1_dt = round(f1_score(y_test,pred_test_dt,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_dt )\n",
    "print('Precision Score  : ',precision_dt )\n",
    "print('Recall Score     : ', recall_dt)\n",
    "print('f1-Score         : ',f1_dt )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d58de7",
   "metadata": {},
   "source": [
    "### 3. RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING NECESSARY LIBRARIES FOR RANDOM FOREST\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = {'n_estimators':15,'class_weight': \"balanced\",'n_jobs':-1,'random_state':42}\n",
    "RF_classifier = RandomForestClassifier(**RF)\n",
    "RF_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_rf = RF_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "train_acc_rf = np.mean(pred_train_rf==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN RANDOM FOREST:\",train_acc_rf)\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_rf = RF_classifier.predict(x_test)\n",
    "#Accuracy On Test Data\n",
    "test_acc_rf = np.mean(pred_test_rf==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN RANDOM FOREST:\",test_acc_rf )\n",
    "\n",
    "#Confusion Matrix\n",
    "rf_cm = confusion_matrix(y_test,pred_test_rf)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF RANDOM FOREST:\\n\", classification_report(y_test,pred_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rf = round(accuracy_score(y_test,pred_test_rf),4)\n",
    "precision_rf = round(precision_score(y_test,pred_test_rf,average = 'macro'),4)\n",
    "recall_rf = round(recall_score(y_test,pred_test_rf,average = 'macro'),4)\n",
    "f1_rf = round(f1_score(y_test,pred_test_rf,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_rf )\n",
    "print('Precision Score  : ',precision_rf )\n",
    "print('Recall Score     : ', recall_rf)\n",
    "print('f1-Score         : ',f1_rf )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50088e0",
   "metadata": {},
   "source": [
    "### 4. MULTINOMIAL NAVIE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b3d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING NECESSARY LIBRARIES FOR MULTINOMIAL NAVIE BAYES\n",
    "from sklearn.naive_bayes import MultinomialNB as MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36c3db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier_mb = MB()\n",
    "classifier_mb.fit(x_train,y_train)\n",
    "\n",
    "#Predicting On Train Data\n",
    "pred_train_mb = classifier_mb.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "train_acc_mb = np.mean(pred_train_mb==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN MULTINOMIAL NAVIE BAYES:\", train_acc_mb)\n",
    "\n",
    "#Predicting On Test Data\n",
    "pred_test_mb = classifier_mb.predict(x_test)\n",
    "#Accuracy On Test Data\n",
    "test_acc_mb = np.mean(pred_test_mb==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN MULTINOMIAL NAVIE BAYES:\", test_acc_mb)\n",
    "\n",
    "#Confusion Matrix\n",
    "mb_cm = confusion_matrix(y_test,pred_test_mb)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF MULTINOMIAL NAVIE BAYES:\\n\", classification_report(y_test,pred_test_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932754c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mb = round(accuracy_score(y_test,pred_test_mb),4)\n",
    "precision_mb = round(precision_score(y_test,pred_test_mb,average = 'macro'),4)\n",
    "recall_mb = round(recall_score(y_test,pred_test_mb,average = 'macro'),4)\n",
    "f1_mb = round(f1_score(y_test,pred_test_mb,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_mb )\n",
    "print('Precision Score  : ',precision_mb )\n",
    "print('Recall Score     : ', recall_mb)\n",
    "print('f1-Score         : ',f1_mb )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79451de4",
   "metadata": {},
   "source": [
    "### 5. SUPPORT VECTOR MACHINE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTING NECESSARY LIBRARIES FOR SUPPORT VECTOR MACHINE\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25299d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_classifier = (SVC(kernel='linear'))\n",
    "svm_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting On Train Data\n",
    "pred_train_svm = svm_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "train_acc_svm = np.mean(pred_train_svm==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN SUPPORT VECTOR MACHINE:\",train_acc_svm )\n",
    "\n",
    "#Prediciting On Test Data\n",
    "pred_test_svm = svm_classifier.predict(x_test)\n",
    "#Accuracy On Test Data\n",
    "test_acc_svm = np.mean(pred_test_svm==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN SUPPORT VECTOR MACHINE:\",test_acc_svm)\n",
    "\n",
    "#Confusion Matrix\n",
    "svm_cm = confusion_matrix(y_test,pred_test_svm)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF SUPPORT VECTOR MACHINE:\\n\", classification_report(y_test,pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6c4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_svm = round(accuracy_score(y_test,pred_test_svm),4)\n",
    "precision_svm = round(precision_score(y_test,pred_test_svm,average = 'macro'),4)\n",
    "recall_svm = round(recall_score(y_test,pred_test_svm,average = 'macro'),4)\n",
    "f1_svm = round(f1_score(y_test,pred_test_svm,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_svm )\n",
    "print('Precision Score  : ',precision_svm )\n",
    "print('Recall Score     : ', recall_svm)\n",
    "print('f1-Score         : ',f1_svm )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a280b613",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.suptitle(\"Confusion Matrixes\", fontsize=18)\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.title(\"LOGISTIC REGRESSION\")\n",
    "sns.heatmap(logistic_cm, cbar=False, annot=True, cmap=\"mako\",  fmt=\"d\")\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.title(\"DECISION TREE\")\n",
    "sns.heatmap(dt_cm, cbar=False, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.title(\"RANDOM FOREST CLASSIFICATION\")\n",
    "sns.heatmap(rf_cm, cbar=False, annot=True, cmap=\"BuPu\", fmt=\"d\")\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.title(\"NaiveBayes Classification\")\n",
    "sns.heatmap(mb_cm, cbar=False, annot=True, cmap=\"Greens\", fmt=\"d\")\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.title(\"SVM Classification\")\n",
    "sns.heatmap(svm_cm, cbar=False, annot=True, cmap=\"YlGnBu\",  fmt=\"d\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77411f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'Classifier' : ['LOGISTIC REGRESSION', 'DECISION TREE', 'RANDOM FOREST', 'MULTINOMIAL NAIVE BAYES', 'SUPPORT VECTOR MACHINE'], 'Accuracy_Score' : [accuracy_log, accuracy_dt, accuracy_rf, accuracy_mb, accuracy_svm], 'Precision_Score' : [precision_log, precision_dt, precision_rf, precision_mb, precision_svm], 'Recall_Score' : [recall_log, recall_dt, recall_rf, recall_mb, recall_svm], 'F1-Score' : [f1_log, f1_dt, f1_rf, f1_mb, f1_svm]}\n",
    "table = pd.DataFrame(table)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a22e22",
   "metadata": {},
   "source": [
    "### ACCURACY COMPARISON PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4df616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "plt.figure(figsize=(15,6))\n",
    "ax= sns.barplot(x=table.Classifier, y=table.Accuracy_Score, palette =sns.color_palette(\"Set2\") )\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)\n",
    "plt.xlabel('Classification Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Scores of Classification Models')\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.19, i.get_height()-0.3, \\\n",
    "            str(round((i.get_height()), 4)), fontsize=15, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e97909",
   "metadata": {},
   "source": [
    "### FINALIZING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca42c19",
   "metadata": {},
   "source": [
    "#### We finalize RANDOM FOREST as it gives 100% Accuracy. Random Forest fits the model in Resume Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7aa42",
   "metadata": {},
   "source": [
    "#### Deployment Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388194e",
   "metadata": {},
   "outputs": [],
   "source": [
    " dump(RF ,open('Random_Forest_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load(open('Random_Forest_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f01cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
